\section{Introduction}
MapReduce~\cite{mr} and its most popular implementation Hadoop~\cite{hadoop}
have become the dominant distributed processing framework for big data
analytics. In contrast to the ease-of-use and scalibility of Hadoop, researchers
have found limitations of the MapReduce framework such as a lack of inter-process
communication and poor performance on handling iterative computations. For
example, X. Lu et al~\cite{xlu} found that the message latency of MPI is about
100 times less than Hadoop primitives. Additionally, the average peak bandwidth of MPI is
about 100 times higher than Hadoop RPC -- the fundamental communication
mechanism in Hadoop. Clearly, for communication intensive applications, the well established Message Passing
Interface (MPI)~\cite{mpi2012} is more suitable due to its ability to support
any communication pattern.
 
Moreover, there exists data analytics workflows such as
Metagenomics~\cite{meta} that consist of both compute- and communication-intensive
computations. To better conduct such workflows and to avoid data
movement between clusters~\cite{catch}, resource coordination platforms such as
Mesos~\cite{mesos}, Omega~\cite{omega}, YARN~\cite{yarn2013} enable different
programming paradigms including MPI and MapReduce to co-exist in the same
cluster. Though not realized yet, hosting MPI and Hadoop in the same cluster is
highly promising. For example, YARN claims to embrace MPI as a first class citizen.

One of the biggest challenges of co-hosting MPI and Hadoop is to decide the
underlying shared file system. As a big feature of the MPI-2 standard~\cite{mpi2012},
MPI-IO provides parallel IO support to MPI programs and enables MPI to process
data-intensive workloads as well. Currently, such support requires an underlying
network/parallel file system such as NFS~\cite{nfs1}, PVFS~\cite{pvfs},
Lustre~\cite{lustre}, GPFS~\cite{gpfs} to achieve the best performance. However,
these file systems are focused on optimization for MPI-IO~\cite{mpipvfs,
mpilustre1, mpigpfs} and have a big network overhead on hosting Hadoop with the
absence of data locality~\cite{hadooplustre}. IBM's GPFS is originally designed
as a SAN file system. The data is striped and placed in a round-robin
fashion~\cite{gpfs}, which prevents it from being used in Hadoop. With support
for File Placement Optimization (FPO), GPFS-FPO makes it possible to efficiently
support Hadoop.  However, GPFS is shipped with IBM SP system and is not
available as open source like Lustre. Moreover, IBM tailors MPI-IO according to
GPFS in their own MPI implementation~\cite{mpigpfs}, which is not supported in
more wildly used implementations such as MPICH~\cite{mpich} and
OpenMPI~\cite{openmpi}.

Another solution is to support MPI-IO on top of the distributed file systems
used by MapReduce such as GFS~\cite{gfs} and HDFS~\cite{hdfs}. HDFS is integrated
inherently in Hadoop releases and is the default file system used in the Hadoop
community. By bringing MPI to HDFS, it is possible to keep existing applications
in Hadoop ecosystem without any changes. C. Cranor et al~\cite{CMU-PDL-12-115} explores the
performance of MPI-IO on HDFS using PLFS. However, HDFS is supported as a
component of PLFS and no data locality is achieved for MPI jobs. As far as we
know, there is no such work on supporting MPI on top of HDFS directly. This
project focuses on exploring the feasibility and performance of enabling MPI-IO
on top of HDFS using existing technologies. In this work, we explore and evaluate
the existing methods including FuseDFS~\cite{fuse}, Native Library~\cite{lib},
HDFS-NFS-Proxy~\cite{proxy} mainly on whether they support MPI-IO and how
well they perform. Furthermore, we design and develop
{\proj}, an extension to current MPI-IO that supports direct access to HDFS for
MPI applications. {\proj} uses the native library provided by HDFS and provides a
seamless user experience. In order to evaluate the performance, we also
developed a MPI-IO benchmark that reports read and write bandwidth. This report
reflects the difficulties we encountered, whether each method can be adopted by
MPI-IO, and how well they perform. 

More specifically, our contribution in this study is as follows:
\begin{itemize}
\item We perform an MPI-IO support study of existing methods we are aware of. This
	is the first study of directly support MPI-IO on top of HDFS as far as
	we know (Section~\ref{sec:bg}).
\item We identify the fundamental limitation of HDFS that prevents parallel
	write operations. We discover this limitation in several methods that we
	explore (Section~\ref{sec:impl}).
\item We design and implement {\proj}, an extension to MPI-IO that seamlessly
	supports HDFS file read/write operations for MPI applications 
	(Section~\ref{sec:impl}). The code is available at \url{github.com/Kimahriman/mpihdfs}
\item We develop an MPI-IO benchmark that measures read/write bandwidth, and
	we perform a thorough performance study on {\proj} and the existing
	methods (Section~\ref{sec:exp}).
\end{itemize}
