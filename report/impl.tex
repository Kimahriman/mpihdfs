\section{Design and Implementation}
Our goal was to provide a convenient solution for interacting with HDFS through MPI. Our solution allows unmodified MPI programs to access HDFS. This is done by wrapping all calls to MPI I/O functions and modifying them to interact with HDFS instead of a locally mounted file system. Our wrapping code interacts with HDFS through the HDFS native library. This sections describes the native library, its limitations, and how we use it in our wrapped MPI function calls to enable this seamless integration.

\subsection{HDFS Native Library}
The HDFS native library is included in the Hadoop distribution. It can typically be found at \texttt{\$HADOOP\_HOME/lib/native}, with the static version \texttt{libhdfs.a} and shared version \texttt{libhdfs.so}. The associated header file is found at \texttt{\$HADOOP\_HOME/include/hdfs.h}. These native libraries allow native code to interact with a running HDFS. This is perfect for interacting with MPI frameworks intended for use in C or C++ programs. Many popular MPI frameworks, such as MPICH~\cite{mpich} and OpenMPI~\cite{openmpi} are designed for use with this native code. We have chosen to implement our approach using MPICH due to [reason and source?]. Table \ref{table:libhdfs} lists the important function prototypes of the HDFS native library needed to map MPI file operations onto HDFS.

\begin{table}[ht]
\caption{Key HDFS Native Functions}
{\ttfamily
\begin{tabular}{l}
\hline\hline
hdfsFS hdfsConnect(const char* nn, tPort port); \\
int hdfsDisconnect(hdfsFS fs); \\
hdfsFile hdfsOpenFile(hdfsFS fs, const char* path, int flags,
                          int bufferSize, short replication, tSize blocksize); \\
int hdfsCloseFile(hdfsFS fs, hdfsFile file); \\
int hdfsSeek(hdfsFS fs, hdfsFile file, tOffset desiredPos); \\
tOffset hdfsTell(hdfsFS fs, hdfsFile file); \\
tSize hdfsRead(hdfsFS fs, hdfsFile file, void* buffer, tSize length); \\
tSize hdfsPread(hdfsFS fs, hdfsFile file, tOffset position,
                    void* buffer, tSize length); \\
tSize hdfsWrite(hdfsFS fs, hdfsFile file, const void* buffer,
                    tSize length); \\
\hline\hline
\end{tabular}
}
\label{table:libhdfs}
\end{table}
					
\texttt{hdfsConnect} creates the initial connection to a running HDFS file system, and requires URL and port number. It returns an \texttt{hdfsFS} object that is required in all file operations to interact with any file from that file system. \texttt{hdfsDisconnect} ends this created connection. \texttt{hdfsOpenFile} returns a handle to an file on a particular file system, either opening the file for reading or writing. This handle is a \texttt{hdfsFile} object that is required, in addition to the \texttt{hdfsFS} object, for all file operations. The remaining functions behave as expected in any file system API. \texttt{hdfsPread} is the positional read, which returns data from the file at a specific offset. \texttt{hdfsRead} simply reads from the current file position, which is changed after previous \texttt{hdfsRead} calls or when invoking \texttt{hdfsSeek}.

The HDFS native library also provides many other functions for interacting with the file system, such as reading or altering file attributes, copying or deleting files, etc. MPI I/O provides little of their own ways to perform these actions, so it was not necessary to use these parts of the HDFS native library. An MPI program could performs these tasks using another file system API. If an HDFS file system is not specially mounted using one of the techniques mentioned earlier, clearly these operations would not work. An extension could be written that allows for simpler access to these attribute functions. This paper simply focuses on the actual file reading and writing operations.

\subsection{Limitations}
While this library provides many simple and useful ways for interacting with an HDFS file system, it does not provide solutions for any of the inherit limitations of HDFS. The most important of which: random writes. The library puts many restrictions in place to make sure this cannot be done. First, files can only be opened in either read-only mode or write-only mode. With the write-only mode, you have two additional options, create the file (and erase any previous file of this name) or append to an existing file. Second, while there is \texttt{hdfsPread}, clearly there is no \texttt{hdfsPwrite}. Finally, \texttt{hdfsSeek} can only be called on files opened in read-only mode. Obviously any \texttt{hdfsWrite} called on a read-only file will fail. We do not provide a ground-breaking solution to this issue, and instead provide limited write support back to HDFS, as well as the ability to interact with with HDFS and a non-HDFS file system simultaneously with only the MPI I/O API. With this, if users are unable to work with the limited writing facilities, they can write normally to another file system, possibly copying the data back to HDFS later if necessary.

\subsection{Hooking Library}
Our goal was to provide an extremely simple approach to allowing HDFS access from MPI programs. We do not require MPI applications to be compiled in a certain way or with one of our provided libraries. Instead, we dynamically catch all MPI I/O function calls at runtime to modify their behavior. Very little effort is required on the part of the user. The provided script \texttt{mpihdfs.sh} simply needs to be used to initiate MPI programs. The arguments passed to the script should simply be the \texttt{mpiexec} or \texttt{mpirun} call that would normally be used. An example invocation would be \texttt{./mpihdfs.sh mpiexec -n 4 -machinefile machinefile ./MPIProgram}. This script simply requires location of three dynamic libraries: the native library that comes with standard Hadoop installations, \texttt{libhdfs.so}, a Java Virtual Machine library that comes with Java installations, \texttt{libjvm.so}, and our hooking library, \texttt{libmpihdfs.so}. This is all that a user must provide in order to start interacting with HDFS through their MPI programs. The typical location of these files are provided in the readme that comes with our distribution.

The script allows our library to receive the MPI file calls by prioritizing our library over the actual MPI library during program startup. This is achieved using the \texttt{LD_PRELOAD} environment variable. More information about dynamic linking and library preloading can be found in \cite{ld.so}. In our library, we have defined our own version of every single MPI_File function, even those we have not implemented. Defining every function lets us ensure there is no mix up going between our version of MPI functions and the actual MPI functions. This ensures a cleaner failure if an unsupported function is envoked, rather than unpredictable behavior. 

Just as the HDFS native library functions operate on an \texttt{hdfsFile} object, MPI file operations operate on an \texttt{MPI_File} object, which is returned as an argument from \texttt{MPI_File_open}. The wrapper functions essentially hijack this \texttt{MPI_File} object to allow state to be stored between various calls to these wrapping functions. An \texttt{MPI_File} object is simply a \texttt{typedef}'d pointer to another file object, which allows our library to simply have this point to our own object instead of the actual MPI object. This is the reason unpredictable behavior would occur if the non-MPI object stored in the \texttt{MPI_File} pointer was passed to an actual MPI file function. Our wrapper file object is defined as follows:

{\ttfamily
typedef struct
{
	int32_t magic;	// Indicates this is HDFS object
	hdfsFS fs;	// HDFS file system object
	hdfsFile file;	// HDFS file object
	char *filename; // Name of file in HDFS
	int mode;	// Mode for opening in HDFS
	int amode;	// Mode for opening in MPI
} hdfsFile_wrapper;
}

The \texttt{magic} field is what allows the various wrapper functions to recognize 
